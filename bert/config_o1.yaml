seed: 42

data:
  train_jsonl: "train.jsonl"
  val_jsonl: "val.jsonl"
  tokenized_dir: "../data/tokenized"

model:
  model_id: "answerdotai/ModernBERT-base"
  max_len_a: 256
  max_len_b: 256

peft:
  enable: true
  lora_r: 8
  lora_alpha: 16
  lora_dropout: 0.05
  target_modules: ["Wqkv", "Wo"]

training:
  output_dir: "../results/runs/modernbert_ac_lora_mixbatch"
  epochs: 3
  
  batch_size: 16
  mix_strategy: "deterministic_concat"
  
  lr: 2.0e-4       
  weight_decay: 0.01
  warmup_ratio: 0.06
  grad_clip: 1.0
  
  lambda_a: 1.0
  lambda_b: 0.3    
  
  pos_weight_a: -1  
  
  device: "cuda"
  num_workers: 2    

quantization:
  enable: false
  load_in_4bit: false
  load_in_8bit: false
  bnb_4bit_quant_type: "nf4"
  torch_dtype: "float16"